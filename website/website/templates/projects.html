{% extends "layout.html" %}

{% block content %}

<center><h1>{{ title }}</h1></center>

<div class="project-year text-container">
    <h2>2019</h2>
    <div class="project">
        <h3>Denso RC8 Python API</h3>
        <p>
            Project developed for Next Generation Systems (NGS) Robotics Lab at the University of Louisville's JB Speed School of Engineering.
            NGS was utilizing LabView for a communication bridge between Robotic Operating System (ROS) nodes and a robot's controller (RC8).
            I designed this API to get rid fo the need for LabView and allow direct communication between the ROS nodes and the robot's controller through a TCP port.
        </p>
        <ul>
            <li>
                <a href="{{ url_for('rc8_api') }}">Project Page</a>
            </li>
            <li>
                <a href="https://github.com/jtcass01/denso_api">Git Repository (needs to be updated)</a>
            </li>
        </ul>
    </div>
</div>

<div class="project-year text-container">
    <h2>2018</h2>
    <div class="project">
        <h3>Sign-Interfaced Machine Operating Network (SIMON)</h3>
        <h5>Personal Project</h5>
        <h4>Abstract (v1.2):</h4>
        <p>
            The purpose of the Sign-Interfaced Machine Operating Network, or SIMON, is to develop a machine learning classifier capable of detecting a discrete set of American Sign Language (ASL) presentations from captured images of a hand and producing a desired response on another system.
            SIMON can utilize a variety of neural networks (nets) for producing its predictions including a classic deep neural net and a ResNet50 convolutional model.
            SIMON’s neural nets were trained on 6 targets using 1200 images (200 of each representation).
            The training and test sets included 1080 and 120 images respectively.
            SIMON utilizes its neural nets to produce a discrete value from an image input matching the target’s class enumeration.
            Images for demonstration were taken using a laptop webcam.
            Predictions are represented in ASCII and are sent across a serial connection to a response machine.
            This project created a response machine from a Raspberry Pi Model 3 B+, a 5050 LED light strip, and a button.
            The goal of this project was to produce the correct color response from the LED light strips given an image containing an ASL representation included in our models’ training.
            This goal was accomplished at its most baseline level although there were some issues and inconsistencies in the neural nets performances including differences in data distributions from training to production as well as distortions in the production data due to preprocessing techniques.
            SIMON was developed using Python 3.6 as well as a variety of 3rd party modules and tested on both Windows 10 and Ubuntu 17.
        </p>

        <ul>
            <li>
                <a href="{{ url_for('simon') }}">Project Page</a>
            </li>
            <li>
                <a href="https://github.com/jtcass01/SIMON">Git Repository</a>
            </li>
            <li>
                <a href="https://www.youtube.com/watch?v=DxSEFz9Di6I">Video Demonstration</a>
            </li>
        </ul>
    </div>
</div>

<div class="project-year text-container">
    <h2>2017</h2>
    <div class="project">
        <h3>Variable Drag System (VDS)</h3>
        <p>
            The Variable Drag System was developed with River City Rocketry (RCR) for the NASA Student Launch (NSL) competition.
            It is an altitude control system that uses a a motor to actuate blades causing a desired change in drag.
            I designed and tested the data acquisition system before I left for my first internship at NASA.
            The PID motor controller and kalman filter were implemented by Ben Stringer.
            The year RCR won first place in NSL, the VDS performed very well achieving a desired apogee 22 feet off of our goal of one mile.
        </p>
        <ul>
            <li>
                <a href="{{ url_for('vds') }}">Project Page</a>
            </li>
            <li>
                <a href="https://github.com/jtcass01/VDS2_0">Git Repository (Only DAQ system)</a>
            </li>
            <li>
                <a href="https://www.youtube.com/watch?v=0kP2HiFFtP0">Video Demonstration</a>
            </li>
        </ul>
    </div>
</div>

{% endblock %}
